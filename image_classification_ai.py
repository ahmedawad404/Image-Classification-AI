# -*- coding: utf-8 -*-
"""Image-Classification-AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R1CVbNtwbf-iC9M3r0muRr5a1t1hUa9x
"""

from google.colab import files
files.upload()
import os
os.makedirs('/root/.kaggle', exist_ok=True)
os.rename('kaggle.json', '/root/.kaggle/kaggle.json')
os.chmod('/root/.kaggle/kaggle.json', 600)

!kaggle datasets download -d robinreni/house-rooms-image-dataset

!unzip house-rooms-image-dataset.zip -d /content/

import torch
import torch.nn as nn
from torch.utils.data import Dataset ,DataLoader
from torchvision.transforms import transforms
import torchvision.models as models

image_size = (224,224)
device = "cuda" if torch.cuda.is_available() else "cpu"
device

import torchvision.transforms as transforms

# حجم الصورة
image_size = (224, 224)

# Data Augmentation - التحسينات المضافة
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),  # اقتصاص عشوائي بنسبة 80% - 100%
    transforms.RandomHorizontalFlip(p=0.5),  # قلب الصورة أفقيًا
    transforms.RandomVerticalFlip(p=0.3),  # قلب الصورة عموديًا (أقل استخدامًا من الأفقي)
    transforms.RandomRotation(20),  # تدوير عشوائي ±20 درجة
    transforms.RandomAffine(degrees=0, shear=10, scale=(0.8, 1.2)),  # تعديلات في الإمالة والتحجيم
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # تغيير الإضاءة والتباين والتشبع
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# بدون Augmentation للـ Validation/Test
test_transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

transform = {
    "train_transform": train_transform,
    "val_transform": test_transform
}

import os
import shutil
from sklearn.model_selection import train_test_split

# Define paths
input_dir = "/content/House_Room_Dataset"
output_dir = "/content/split_dataset"

train_dir = os.path.join(output_dir, "train")
test_dir = os.path.join(output_dir, "test")

# Create output directories
os.makedirs(train_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

# Loop through each class folder
for room in os.listdir(input_dir):
    room_path = os.path.join(input_dir, room)
    if os.path.isdir(room_path):  # Ensure it's a folder
        images = os.listdir(room_path)

        # Split data
        train_images, test_images = train_test_split(images, test_size=0.1, random_state=42)

        # Create room directories in train and test
        os.makedirs(os.path.join(train_dir, room), exist_ok=True)
        os.makedirs(os.path.join(test_dir, room), exist_ok=True)

        # Move train images
        for img in train_images:
            shutil.copy(os.path.join(room_path, img), os.path.join(train_dir, room, img))

        # Move test images
        for img in test_images:
            shutil.copy(os.path.join(room_path, img), os.path.join(test_dir, room, img))

print("Data split successfully!")

#import os
#import shutil


train_path = "/content/split_dataset/train"

destination_folder = "/content/split_dataset/train_all"

os.makedirs(destination_folder, exist_ok=True)

for folder in os.listdir(train_path):
    folder_path = os.path.join(train_path, folder)

    if os.path.isdir(folder_path):
        print(f"نقل الصور من: {folder}")

        for image in os.listdir(folder_path):
            image_path = os.path.join(folder_path, image)

            shutil.move(image_path, os.path.join(destination_folder, image))

print("done")

print(f"عدد الصور في '{destination_folder}':", len(os.listdir(destination_folder)))

#import os
train_path='/content/split_dataset/train_all'
dirs=os.listdir(train_path)
len(dirs)

train_path

bat=[path for path in dirs if path.startswith('bat')]
bed=[path for path in dirs if path.startswith('bed')]
din=[path for path in dirs if path.startswith('din')]
kit=[path for path in dirs if path.startswith('kit')]
liv=[path for path in dirs if path.startswith('liv')]
print(len(bat),len(bed),len(din),len(kit),len(liv))
allpath=bat+bed+din+kit+liv
traiin_path=bat[98:]+bed[98:489]+din[98:489]+kit[98:489]+liv[98:489]
vall_path=bat[0:98]+bed[:98]+din[:98]+kit[:98]+liv[:98]

import random

random.shuffle(traiin_path)
random.shuffle(vall_path)

from PIL import Image
bath=os.path.join(train_path,bat[0])
img=Image.open(bath)
img

class dataset(Dataset):
    def __init__(self,path,transform=None,is_train=True):
        self.path=path
        self.transform=transform
        self.is_train=is_train


    def __getitem__(self,index):
        fullpath=os.path.join(train_path,self.path[index])

        img=Image.open(fullpath)

        label=self.path[index][0:3]
        if self.transform:
            if self.is_train:
                img = self.transform['train_transform'](img)
            else:
                img = self.transform['val_transform'](img)
        if label=='bat':
            label=0
        elif label=='bed':
            label=1
        elif label=='din':
            label=2
        elif label=='kit':
            label=3
        elif label=='liv':
            label=4
        return img,label

    def __len__(self):
        return len(self.path)

train_data=dataset(traiin_path,transform)
val_data=dataset(vall_path,transform, is_train=False)

trainloader=DataLoader(train_data,shuffle=True,batch_size=8)
valloader=DataLoader(val_data,shuffle=False,batch_size=8)

((next(iter(trainloader))))[1]

import matplotlib.pyplot as plt
img=train_data[0][0]
plt.imshow(img.permute(1,2,0))

train_data[0][1]

# !pip install efficientnet-pytorch

# import torch
# from efficientnet_pytorch import EfficientNet

# # Load EfficientNet-B0 with pretrained weights
# model = EfficientNet.from_pretrained('efficientnet-b5')

# # Modify the final layer for your specific task (e.g., 5 classes)
# model._fc = torch.nn.Linear(model._fc.in_features, 5)

# # Send model to GPU if available
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = model.to(device)

# # Print the model to verify
# print(model)

import torch
import torch.nn as nn
import torchvision.models as models

model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2)

for param in model.parameters():
    param.requires_grad = False

num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 5)

for param in model.fc.parameters():
    param.requires_grad = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.optim.lr_scheduler import ReduceLROnPlateau

class DeepModel(nn.Module):
    def __init__(self):
        super(DeepModel, self).__init__()

        # Load pretrained ResNet backbone
        resnet = models.resnet50(weights="IMAGENET1K_V2")

        # Extract ResNet feature layers
        self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # Exclude the fully connected layers

        # Optionally, fine-tune some of the layers
        for param in self.backbone[-2:].parameters():  # Fine-tune the last few layers
            param.requires_grad = True

        # Feature pooling
        self.pool = nn.AdaptiveAvgPool2d((1, 1))

        # Fully connected layers
        self.fc1 = nn.Linear(resnet.fc.in_features, 1024)
        self.bn1 = nn.BatchNorm1d(1024)
        self.dropout1 = nn.Dropout(0.5)  # Increased dropout

        self.fc2 = nn.Linear(1024, 512)
        self.bn2 = nn.BatchNorm1d(512)
        self.dropout2 = nn.Dropout(0.5)  # Increased dropout

        self.fc3 = nn.Linear(512, 5)  # 5 classes (adjust based on your task)

    def forward(self, x):
        x = self.backbone(x)
        x = self.pool(x)
        x = torch.flatten(x, 1)

        x = self.bn1(self.fc1(x))
        x = nn.LeakyReLU(0.1)(x)  # Leaky ReLU activation
        x = self.dropout1(x)

        x = self.bn2(self.fc2(x))
        x = nn.LeakyReLU(0.1)(x)  # Leaky ReLU activation
        x = self.dropout2(x)

        x = self.fc3(x)

        return x
        # Initialize the model
model = DeepModel().to(device)

# Optimizer and scheduler
optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)

# ReduceLROnPlateau scheduler to reduce the learning rate when validation loss plateaus
scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)

# Define the loss function (cross-entropy for multi-class classification)
criterion = nn.CrossEntropyLoss()

num_epochs = 20
lr = .0001

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)

def train_epoch():
    epoch_loss = 0
    correct = 0
    total = 0

    for i, (images, labels) in enumerate(trainloader):
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        out = model(images)
        loss = criterion(out, labels)
        epoch_loss += loss.item()

        # Compute accuracy
        _, predicted = torch.max(out.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if i % 25 == 0:
            print(f"step [{i+1} / {len(trainloader)}]")

    epoch_accuracy = correct / total * 100
    return epoch_loss / len(trainloader), epoch_accuracy

def get_val_loss():
    epoch_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for i, (images, labels) in enumerate(valloader):
            images = images.to(device)
            labels = labels.to(device)

            out = model(images)
            loss = criterion(out, labels)
            epoch_loss += loss.item()

            _, predicted = torch.max(out.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    epoch_accuracy = correct / total * 100
    return epoch_loss / len(valloader), epoch_accuracy

train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []
best_score = float('inf')
tol = 0

for epoch in range(num_epochs):
    print(f'Epoch {epoch+1}')

    model.train(True)
    avg_train_epoch_loss, train_accuracy = train_epoch()

    model.eval()
    avg_val_epoch_loss, val_accuracy = get_val_loss()

    if avg_val_epoch_loss < best_score:
        best_score = avg_val_epoch_loss
        torch.save(model.state_dict(), f'model_{epoch+1}.pth')
        tol = 0
    else:
        tol += 1
        if tol >= 4:
            print("Early stopping due to no improvement in validation loss.")
            break

    train_losses.append(avg_train_epoch_loss)
    val_losses.append(avg_val_epoch_loss)
    train_accuracies.append(train_accuracy)
    val_accuracies.append(val_accuracy)

    # Print the results for the current epoch
    print(f'Epoch: {epoch+1} --- Avg Train Loss = {avg_train_epoch_loss:.4f} --- Train Accuracy = {train_accuracy:.2f}%')
    print(f'Epoch: {epoch+1} --- Avg Val Loss = {avg_val_epoch_loss:.4f} --- Validation Accuracy = {val_accuracy:.2f}%')
    print('-' * 100)

# get best model

import matplotlib.pyplot as plt

# Ensure variables have matching lengths
num_epochs = len(train_losses)

# Plot Training and Validation Loss
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='orange', marker='o')
plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='purple', marker='h')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()

# Plot Training and Validation Accuracy
plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', color='orange', marker='o')
plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='purple', marker='h')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.title('Training and Validation Accuracy')
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()

plt.tight_layout()
plt.show()

correct = 0
total = 0
model.eval()  # Set the model to evaluation mode

# Validation loop
with torch.no_grad():
    for inputs, labels in valloader:  # Use the correct validation dataloader
        # Move inputs and labels to the same device as the model
        inputs, labels = inputs.to(device), labels.to(device)

        # Forward pass
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score
        total += labels.size(0)  # Total number of samples
        correct += (predicted == labels).sum().item()  # Count correct predictions

# Calculate and print validation accuracy
accuracy = 100 * correct / total
print(f'Validation Accuracy: {accuracy:.2f}%')

correct = 0
total = 0
# Load test dataset
testset = ImageFolder(root='./split_dataset/test', transform=test_transform)
testloader = DataLoader(testset, batch_size=32, shuffle=False)

with torch.no_grad():
    for inputs, labels in testloader:
        # Move inputs and labels to the same device as the model
        inputs, labels = inputs.to(device), labels.to(device)

        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Test Accuracy: {100 * correct / total:.2f}%')



from sklearn.metrics import confusion_matrix, classification_report
# Get class names
class_names = testset.classes

# Set model to evaluation mode
model.eval()

# Initialize lists to store true and predicted labels
y_true = []
y_pred = []

# Run model on test set
with torch.no_grad():
    for inputs, labels in testloader:
        inputs, labels = inputs.to(device), labels.to(device)

        # Get model predictions
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)

        # Append to lists
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())

# Convert lists to numpy arrays
y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Greens", xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Display the classification report
print("\nClassification Report:\n", classification_report(y_true, y_pred, target_names=class_names))

from torchvision.datasets import ImageFolder
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import matplotlib.pyplot as plt
import numpy as np
import torch
import torchvision

# Function to display an image
def imshow(img):
    img = img / 2 + 0.5  # Unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.axis('off')

# Function to display test images with predictions and ground truth labels
def plot_test_predictions(model, testloader, class_names, num_images=5):
    model.eval()  # Set the model to evaluation mode
    displayed_classes = {class_name: 0 for class_name in class_names}  # Track images per class
    total_images_shown = 0

    plt.figure(figsize=(12, num_images * 3))

    with torch.no_grad():  # Disable gradient computation for evaluation
        for images, labels in testloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)

            # Go through each image and check conditions
            for i in range(images.size(0)):
                true_label = class_names[labels[i].item()]

                # Only display up to 'num_images' per class
                if displayed_classes[true_label] < num_images:
                    plt.subplot(num_images, len(class_names), total_images_shown + 1)
                    imshow(images[i].cpu())  # Display the image

                    # Get the predicted and actual labels
                    pred_label = class_names[predicted[i].item()]

                    # Set color based on prediction correctness
                    color = 'green' if true_label == pred_label else 'red'
                    plt.title(f'True: {true_label}\nPred: {pred_label}', color=color)

                    displayed_classes[true_label] += 1
                    total_images_shown += 1

                # Stop if we've reached the limit for each class
                if all(count >= num_images for count in displayed_classes.values()):
                    break
            if all(count >= num_images for count in displayed_classes.values()):
                break

    plt.tight_layout()
    plt.show()

# Use the function
plot_test_predictions(model, testloader, testset.classes)